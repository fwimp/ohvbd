% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_extract_vd_byid_chunked.R
\name{get_extract_vd_byid_chunked}
\alias{get_extract_vd_byid_chunked}
\title{Get and parse multiple VecDyn datasets by ID in chunks}
\usage{
get_extract_vd_byid_chunked(
  basereq,
  ids,
  chunksize = 20,
  cols = NA,
  returnunique = FALSE,
  rate = 5
)
}
\arguments{
\item{basereq}{an \link[httr2:request]{httr2 request} object, as generated by \code{\link[=vb_basereq]{vb_basereq()}}.}

\item{ids}{a numeric vector of IDs indicating the particular datasets to download.}

\item{chunksize}{an integer defining the size of chunks to retrieve in one iteration.}

\item{cols}{a character vector of columns to extract from the dataset.}

\item{returnunique}{whether to return only the unique rows within each dataset according to the filtered columns.}

\item{rate}{maximum number of calls to the API per second.}
}
\value{
A dataframe containing the requested data.
}
\description{
Retrieve and parse VecDyn datasets specified by their dataset IDs in batches.

This is not usually necessary (generally you just need \code{\link[=get_vd_byid]{get_vd_byid()}}) but allows one to release data that is not in use from memory. If you would like more control on extraction or parsing then it is best to wrap \code{\link[=get_vd_byid]{get_vd_byid()}} and \code{\link[=extract_vd_data]{extract_vd_data()}} in your own chunker instead.
}
\examples{
\dontrun{
vb_basereq() \%>\%
  get_extract_vd_byid_chunked(c(423,424,425), chunksize = 2, rate=5)
}

}
\author{
Francis Windram
}
